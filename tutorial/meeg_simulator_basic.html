
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Basic usage &#8212; meeg_simulator 0.0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorial/meeg_simulator_basic';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Simulating multivariate effects based on temporal kernel" href="meeg_simulator_kernel.html" />
    <link rel="prev" title="meeg_simulator tutorials" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">MEEG Simulator</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API reference
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API reference
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Basic usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="meeg_simulator_kernel.html">Simulating multivariate effects based on temporal kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="meeg_simulator_intersubject_noise.html">Simulating multivariate effects with intersubject variability</a></li>
<li class="toctree-l1"><a class="reference internal" href="meeg_simulator_effect_size.html">Specifying Multivariate Effect Size</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">meeg_simulator tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Basic usage</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <style>
/* Hide Notebook Titles from Sidebar */
.toctree-wrapper > ul { display: none !important; }
</style><section id="Basic-usage">
<h1>Basic usage<a class="headerlink" href="#Basic-usage" title="Link to this heading">#</a></h1>
<p>Below is a concise, example-driven tutorial that illustrates how to use your toolbox to simulate MEG/EEG data with known “ground truth” effects, then test whether a decoding analysis can successfully detect those effects. This guides new users through the typical workflow: defining an experimental design, specifying when each effect should be present in time, generating data, and finally verifying that a chosen analysis pipeline can uncover the artificially injected effects.</p>
<section id="Motivation-and-Overview">
<h2>Motivation and Overview<a class="headerlink" href="#Motivation-and-Overview" title="Link to this heading">#</a></h2>
<p>One critical challenge in designing analysis pipelines for MEG/EEG data is confirming that the pipeline is both sensitive (i.e., it detects real effects) and specific (i.e., it avoids false alarms). In most cases, it is not known a priori whether or when experimental effects are present in the data, and it is therefore not possible to assess the sensitivity and specificity of analysis pipelines based on the data one is trying to analyse.</p>
<p>This toolbox offers a solution, by allowing users to simulate MEG/EEG data that mimicks the data set that they plan to or have already collected (number of participants, experimental design…), enabling to test that the designed pipelines are capable of detecting the effects of interest.</p>
<p>Specifically, the toolbox allows to:</p>
<ul class="simple">
<li><p>Specify a between-trial design (e.g., two conditions, Condition A and Condition B).</p></li>
<li><p>Inject multivariate effects at particular time windows (e.g., Condition A is active from 100–200 ms, Condition B from 300–400 ms).</p></li>
<li><p>Generate a realistic dataset (with noise, trial variability, and optionally correlated sensor modes).</p></li>
<li><p>Analyze that dataset (e.g., classification, sensor-level univariate tests, source localization, etc.).</p></li>
<li><p>Validate that the pipeline recovers the known effects accurately.</p></li>
</ul>
<p>Below, we walk through a minimal but representative example.</p>
</section>
<section id="1.-Defining-an-Experimental-Design">
<h2>1. Defining an Experimental Design<a class="headerlink" href="#1.-Defining-an-Experimental-Design" title="Link to this heading">#</a></h2>
<p>Imagine we have a simple 2x2 experimental design, in which we presented trials of 2 different categories (say faces and objects) displayed in two different attention condition (attended vs. unattended condition). In each attention condition, we have presented 40 faces and 40 objects, resulting in a total of 160 trials in total. We will specify a design matrix of 160 rows (1 per trial) and with 2 columns:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>Attention</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>face</p></td>
<td><p>attended</p></td>
</tr>
<tr class="row-odd"><td><p>face</p></td>
<td><p>unattended</p></td>
</tr>
<tr class="row-even"><td><p>object</p></td>
<td><p>attended</p></td>
</tr>
<tr class="row-odd"><td><p>object</p></td>
<td><p>unattended</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
</div>
<p>We will create this design matrix, encoding as 1 and -1 each condition (face: 1, object: -1, attended: 1, unattended: -1)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np

# Creating the design matrix of our 2 by two balanced design:
X = np.array([[1, 1, -1, -1] * 40, [1, -1] * 80]).T

# Add descriptors:
cond_names = [&quot;category&quot;, &quot;attention&quot;]
mapping = {
    &quot;category&quot;: {1: &quot;face&quot;, -1: &quot;object&quot;},
    &quot;attention&quot;: {1: &quot;attended&quot;, -1: &quot;unattended&quot;},
}
</pre></div>
</div>
</div>
</section>
<section id="3.-Specifying-Time-Windows-for-the-Effects">
<h2>3. Specifying Time Windows for the Effects<a class="headerlink" href="#3.-Specifying-Time-Windows-for-the-Effects" title="Link to this heading">#</a></h2>
<p>Now let’s imagine that in our design, each stimulus was presented for 0.25s followed by a blank screen for 0.75s, such that each trial lasted 1 sec. And in addition, we have a baseline time window of 0.25s before each stimulus.</p>
<p>For each condition we want to inject an effect (i.e., a multivariate pattern representing the content of interest) at a specific time. Let’s say:</p>
<ul class="simple">
<li><p>Faces vs. objects is active from 100 ms to 200 ms</p></li>
<li><p>Attended vs. unattended is active from 300 ms to 400 ms</p></li>
</ul>
<p>To simulate data accordingly, we need to specify the index for which we want to inject an effect (in our case for the first and the second column of our design matrix), and for each, we need to specify the time window in which we want the effect to be present, like so:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># The &#39;effects&#39; array tells us which columns in X are &#39;active&#39; at each time window.
# Here we say effect 0 =&gt; category, effect 1 =&gt; attention
effects = np.array([0, 1])

# For each effects, define a 2x2 array where each row is [start_ms, end_ms]
t_win = np.array(
    [
        [0.100, 0.200],  # Condition 0 active window
        [0.300, 0.400],  # Condition 1 active window
    ]
)
</pre></div>
</div>
</div>
<p>You may be wondering: what about interactions? You might very well expect that there is an interaction between category and attention: faces vs. objects can only be decoded in the attended and not in the attended condition. We need to extend our design matrix X to include such an interaction:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>interaction = X[:, 0] * X[:, 1]
X = np.column_stack(
    [X, interaction]
)  # Add a column for the interaction between category and attention
</pre></div>
</div>
</div>
<p>So if you want to inject an interaction effect at a particular time point, you simply need to add one more effect (i.e. the third column) at the time point of your choice. To keep things simple here, we will keep the interaction to 0.</p>
</section>
<section id="4.-Simulating-the-Data">
<h2>4. Simulating the Data<a class="headerlink" href="#4.-Simulating-the-Data" title="Link to this heading">#</a></h2>
<p>So far, we have created our design matrix X, we know that a trial lasts from -0.250 to 1.0s from stimulus onset (i.e. 250ms baseline and 1s after stimulus onset), and we have specified when and what effects we want to have. Importantly, we also need to specify the size of our effect. In this toolbox, the effect size is calculated based on the Mahalanobis distance (a measure of separability of multivariate patterns), which depends on the observation noise and the number of sensors. In this
tutorial, we will fix the effect size to 0.5 for each of our effects, which we can easily pick up on based on the parameters we specify below:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>effect_size = [0.5, 0.5]  # An effect of 0.5 for category and attention decoding
</pre></div>
</div>
</div>
<p>We also need to specify the characteristics of our data:</p>
<ul class="simple">
<li><p>n_channels: the number of channels of the MEG/EEG recordings we plan to analyze</p></li>
<li><p>sfreq: the sampling frequency of our signal</p></li>
<li><p>n_subjects: the number of subjects for our virtual data set</p></li>
<li><p>s: observation noise</p></li>
<li><p>ch_cov: the spatial covariance of the data we want to simulate</p></li>
</ul>
<p>The aim of this toolbox is to provide a way to test whether analysis pipelines you have designed are able to detect effects that are actually present in your data. So you have to specify parameters that match your actual data: same number of channels, same number of subjects. For this tutorial, let’s say we are working with an EEG system recording <strong>32 channels</strong> and that we collected <strong>20 participants</strong>.</p>
<p>We also recommend that the observation noise and spatial covariance matches your actual data, as it will ensure that the simulated data are representative of the data that you analyze and that the sensitivity and specificity of your pipeline on the simulated data is representative of how they will perform on your real data. We will see in a later tutorial how you can estimate these parameters from your data, but for now we will keep it simple. We will set the observation noise (i.e. variance) to
0.5, and pretend that there is no spatial covariance:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_channels = 32  # EEG system with 32 electrodes
n_subjects = 20  # Recording from 20 subjects
noise_std = 1 / 2  # Variance of the data
ch_cov = None  # Assuming that the data of each sensor are independent
sfreq = 50  # Simulating data at 50Hz
</pre></div>
</div>
</div>
<p>With everything specified, we are now ready to simulate the data. In addition, we are converting the data to MNE epochs format, which is useful if you plan to analyze the data relying on their functions. We also show how to export to eeglab, in case this is your preferred toolbox.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from multisim import Simulator

sims = Simulator(
    X,  # Design matrix
    noise_std,  # Observation noise
    n_channels,  # Number of channelss
    n_subjects,  # Number of subjects
    -0.25,
    1.0,  # Start and end of epochs
    sfreq,  # Sampling frequency of the data
    t_win,  # Time window of the effects
    effects,  # Which effects
    ch_cov=ch_cov,  # Spatial covariance of the data
    effect_size=effect_size,  # Effect sizes
)
epochs = sims.export_to_mne(X=X[:, :2], cond_names=cond_names, mapping=mapping)

# Alternatively, save to eeglab format
sims.export_to_eeglab(
    X=X[:, :2],
    cond_names=cond_names,
    mapping=mapping,
    root=&quot;./data&quot;,
    fname_template=&quot;sub-{:02d}_task-sim-epo.set&quot;,
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
</pre></div></div>
</div>
</section>
<section id="5.-Vizualizing-the-data:">
<h2>5. Vizualizing the data:<a class="headerlink" href="#5.-Vizualizing-the-data:" title="Link to this heading">#</a></h2>
<p>We can have a quick look at our simulated data. It won’t look like much, given that we have simulated multivariate effects without much else at all. It won’t look like actual MEG/EEG data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>epochs[0].plot_image(picks=&quot;eeg&quot;, combine=&quot;mean&quot;, scalings=dict(eeg=1))
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
combining channels using &#34;mean&#34;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_meeg_simulator_basic_15_1.png" src="../_images/tutorial_meeg_simulator_basic_15_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;Figure size 640x480 with 3 Axes&gt;]
</pre></div></div>
</div>
</section>
<section id="6.-Decoding-analysis">
<h2>6. Decoding analysis<a class="headerlink" href="#6.-Decoding-analysis" title="Link to this heading">#</a></h2>
<section id="6.1.-Within-subject-analysis:">
<h3>6.1. Within subject analysis:<a class="headerlink" href="#6.1.-Within-subject-analysis:" title="Link to this heading">#</a></h3>
<p>We can try to decode each of the labels of interest (face vs. objects and attended vs. unattended) for a given subject and we will see that these effects are present at the expected time points:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
import numpy as np
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from mne.decoding import SlidingEstimator, cross_val_multiscore

# Create the classifier:
clf = make_pipeline(StandardScaler(), SVC())

# Time resolved
time_decod = SlidingEstimator(clf, n_jobs=None, scoring=&quot;roc_auc&quot;, verbose=True)

# Extract the data:
data = epochs[0].get_data()

# Decode faces vs. objects:
cate_lbl = np.array([mapping[&quot;category&quot;][val] for val in X[:, 0]])
scores_category = np.mean(
    cross_val_multiscore(
        time_decod, data, cate_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
    ),
    axis=0,
)

# Decode attended vs. unattended:
att_lbl = np.array([mapping[&quot;attention&quot;][val] for val in X[:, 1]])
scores_attention = np.mean(
    cross_val_multiscore(
        time_decod, data, att_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
    ),
    axis=0,
)

# Plot
fig, ax = plt.subplots()
ax.plot(epochs[0].times, scores_category, label=&quot;category&quot;)
ax.plot(epochs[0].times, scores_attention, label=&quot;attention&quot;)
ax.axhline(0.5, color=&quot;k&quot;, linestyle=&quot;--&quot;, label=&quot;chance&quot;)
ax.set_xlim([epochs[0].times[0], epochs[0].times[-1]])
ax.set_xlabel(&quot;Times&quot;)
ax.set_ylabel(&quot;AUC&quot;)  # Area Under the Curve
ax.legend()
ax.axvline(0.0, color=&quot;k&quot;, linestyle=&quot;-&quot;)
ax.set_title(&quot;Sensor space decoding&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Sensor space decoding&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_meeg_simulator_basic_17_1.png" src="../_images/tutorial_meeg_simulator_basic_17_1.png" />
</div>
</div>
</section>
<section id="6.2.-Group-level-analysis">
<h3>6.2. Group level analysis<a class="headerlink" href="#6.2.-Group-level-analysis" title="Link to this heading">#</a></h3>
<p>We simulated the data of 20 subjects, so we can investigate the evidence for decoding of the experimental manipulations at the group level. First, we need to perform the decoding on every single subject:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from mne.stats import permutation_cluster_1samp_test, bootstrap_confidence_interval

scores_category = []
scores_attention = []

# Loop through each subject:
for epo in epochs:
    # Extract the data:
    data = epo.get_data()
    # Classification of category
    scores_category.append(
        np.mean(
            cross_val_multiscore(
                time_decod, data, cate_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
            ),
            axis=0,
        )
    )
    # Classification of attention:
    scores_attention.append(
        np.mean(
            cross_val_multiscore(
                time_decod, data, att_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
            ),
            axis=0,
        )
    )

scores_category = np.array(scores_category)
scores_attention = np.array(scores_attention)
</pre></div>
</div>
</div>
<p>We can then apply a cluster based permutation test across subjects to find out when we have an effect:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Cluster based permutation test for the category:
T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(
    scores_category - 0.5,
    n_permutations=1024,
    tail=1,
    out_type=&quot;mask&quot;,
    verbose=True,
)
sig_mask_cate = np.zeros(len(epochs[0].times), dtype=bool)
for c, p_val in enumerate(cluster_p_values):
    if p_val &lt; 0.05:
        sig_mask_cate[clusters[c]] = True

# Cluster based permutation test for the attention:
T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(
    scores_attention - 0.5,
    n_permutations=1024,
    tail=1,
    out_type=&quot;mask&quot;,
    verbose=True,
)
sig_mask_att = np.zeros(len(epochs[0].times), dtype=bool)
for c, p_val in enumerate(cluster_p_values):
    if p_val &lt; 0.05:
        sig_mask_att[clusters[c]] = True
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using a threshold of 1.729133
stat_fun(H1): min=-2.1016880577898 max=11.024264070515306
Running initial clustering …
Found 3 clusters
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6a9bcdb086fa4ad7832fb0252edea3a5", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using a threshold of 1.729133
stat_fun(H1): min=-3.7918254118886083 max=13.552409817618754
Running initial clustering …
Found 3 clusters
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "78a25c9d9a274f91a0a5b885174e6044", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>Based on the input to the simulation, we would expect to see a significantly above chance decoding of face vs. object from 0.1 to 0.2 s, and then of attention from 0.3 to 0.4s. Let’s check whether that is the case:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Compute the confidence intervals:
ci_low_cate, ci_up_cate = bootstrap_confidence_interval(scores_category)
ci_low_att, ci_up_att = bootstrap_confidence_interval(scores_attention)

fig, ax = plt.subplots()
ax.plot(epochs[0].times, np.mean(scores_category, axis=0), label=&quot;category&quot;, color=&quot;b&quot;)
ax.fill_between(epochs[0].times, ci_low_cate, ci_up_cate, alpha=0.3, color=&quot;b&quot;)
ax.plot(
    epochs[0].times[sig_mask_cate],
    np.ones(np.sum(sig_mask_cate)) * 0.4,
    marker=&quot;o&quot;,
    linestyle=&quot;None&quot;,
    color=&quot;b&quot;,
)

ax.plot(
    epochs[0].times, np.mean(scores_attention, axis=0), label=&quot;attention&quot;, color=&quot;g&quot;
)
ax.fill_between(epochs[0].times, ci_low_att, ci_up_att, alpha=0.3, color=&quot;g&quot;)
ax.plot(
    epochs[0].times[sig_mask_att],
    np.ones(np.sum(sig_mask_att)) * 0.4,
    marker=&quot;o&quot;,
    linestyle=&quot;None&quot;,
    color=&quot;g&quot;,
)
ax.axhline(0.5, color=&quot;k&quot;, linestyle=&quot;--&quot;, label=&quot;chance&quot;)
ax.set_xlim([epochs[0].times[0], epochs[0].times[-1]])
ax.set_xlabel(&quot;Times&quot;)
ax.legend()
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_meeg_simulator_basic_23_0.png" src="../_images/tutorial_meeg_simulator_basic_23_0.png" />
</div>
</div>
<p>Just as one would expect, we find significant decoding in the expected time windows. This makes designing decoding analysis (or any multivariate techniques such as RSA) very easy, as one can be sure that mistakes crept in, and that the pipeline is sensitive and specific enough</p>
<p>In the next tutorial, we will explore how to make the temporal dynamics of the multivariate signal more realistic, by adding a temporal kernel to our effect</p>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">meeg_simulator tutorials</p>
      </div>
    </a>
    <a class="right-next"
       href="meeg_simulator_kernel.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Simulating multivariate effects based on temporal kernel</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Motivation-and-Overview">Motivation and Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Defining-an-Experimental-Design">1. Defining an Experimental Design</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#3.-Specifying-Time-Windows-for-the-Effects">3. Specifying Time Windows for the Effects</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#4.-Simulating-the-Data">4. Simulating the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#5.-Vizualizing-the-data:">5. Vizualizing the data:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#6.-Decoding-analysis">6. Decoding analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#6.1.-Within-subject-analysis:">6.1. Within subject analysis:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#6.2.-Group-level-analysis">6.2. Group level analysis</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/tutorial/meeg_simulator_basic.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, Alex Lepauvre.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>