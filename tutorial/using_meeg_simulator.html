
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Motivation and Overview &#8212; meeg simulator 0.0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorial/using_meeg_simulator';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">meeg simulator 0.0.1 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../reference/index.html">
    API reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../reference/index.html">
    API reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Motivation and Overview</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>Below is a concise, example-driven tutorial that illustrates how to use your toolbox to simulate MEG/EEG data with known “ground truth” effects, then test whether a decoding analysis can successfully detect those effects. This guides new users through the typical workflow: defining an experimental design, specifying when each effect should be present in time, generating data, and finally verifying that a chosen analysis pipeline can uncover the artificially injected effects.</p>
<section id="Motivation-and-Overview">
<h1>Motivation and Overview<a class="headerlink" href="#Motivation-and-Overview" title="Link to this heading">#</a></h1>
<p>One critical challenge in designing analysis pipelines for MEG/EEG data is confirming that the pipeline is both sensitive (i.e., it detects real effects) and specific (i.e., it avoids false alarms). In most cases, it is not known a priori whether or when experimental effects are present in the data, and it is therefore not possible to assess the sensitivity and specificity of analysis pipelines based on the data one is trying to analyse.</p>
<p>This toolbox offers a solution to this issue, by allowing users to simulate MEG/EEG data that mimicks the data set that they plan to or have already collected (number of participants, experimental design…), enabling to test that the designed pipelines are capable of detecting the effects of interest.</p>
<p>Specifically, the toolbox allows to:</p>
<ul class="simple">
<li><p>Specify a between-trial design (e.g., two conditions, Condition A and Condition B).</p></li>
<li><p>Inject multivariate effects at particular time windows (e.g., Condition A is active from 100–200 ms, Condition B from 300–400 ms).</p></li>
<li><p>Generate a realistic dataset (with noise, trial variability, and optionally correlated sensor modes).</p></li>
<li><p>Analyze that dataset (e.g., classification, sensor-level univariate tests, source localization, etc.).</p></li>
<li><p>Validate that the pipeline recovers the known effects accurately.</p></li>
</ul>
<p>Below, we walk through a minimal but representative example.</p>
</section>
<section id="1.-Defining-an-Experimental-Design">
<h1>1. Defining an Experimental Design<a class="headerlink" href="#1.-Defining-an-Experimental-Design" title="Link to this heading">#</a></h1>
<p>Imagine we have a simple 2x2 experimental design, in which we presented trials of 2 different categories (say faces and objects) in two different attention condition (attended vs. unattended condition). In each attention condition, we have presented 40 faces and 40 objects, resulting in a total of 160 trials in total. We will specify a design matrix of 160 rows (1 per trial) and with 2 columns:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>Attention</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>face</p></td>
<td><p>attended</p></td>
</tr>
<tr class="row-odd"><td><p>face</p></td>
<td><p>unattended</p></td>
</tr>
<tr class="row-even"><td><p>object</p></td>
<td><p>attended</p></td>
</tr>
<tr class="row-odd"><td><p>object</p></td>
<td><p>unattended</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
</div>
<p>We will create this design matrix, encoding as 1 and -1 each condition (face: 1, object: -1, attended: 1, unattended: -1)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np

# Creating the design matrix of our 2 by two balanced design:
X = np.array([[1, 1, -1, -1] * 40, [1, -1] * 80]).T
</pre></div>
</div>
</div>
</section>
<section id="3.-Specifying-Time-Windows-for-the-Effects">
<h1>3. Specifying Time Windows for the Effects<a class="headerlink" href="#3.-Specifying-Time-Windows-for-the-Effects" title="Link to this heading">#</a></h1>
<p>Now let’s imagine that in our design, each stimulus was presented for 0.25s followed by a blank screen for 0.75s, such that each trial lasted 1 sec. And in addition, we have a baseline time window of 0.25s before each stimulus.</p>
<p>For each condition we want to inject an effect (i.e., a multivariate pattern representing the content of interest) at a specific time. Let’s say:</p>
<ul class="simple">
<li><p>Faces vs. objects is active from 100 ms to 200 ms</p></li>
<li><p>Attended vs. unattended is active from 300 ms to 400 ms</p></li>
</ul>
<p>To simulate data accordingly, we need to specify the index for which we want to inject an effect (in our case for the first and the second column of our design matrix), and for each, we need to specify the time window in which we want the effect to be present, like so:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># The &#39;effects&#39; array tells us which columns in X are &#39;active&#39; at each time window.
# Here we say effect 0 =&gt; category, effect 1 =&gt; attention
effects = np.array([0, 1])

# For each effects, define a 2x2 array where each row is [start_ms, end_ms]
t_win = np.array(
    [
        [0.100, 0.200],  # Condition 0 active window
        [0.300, 0.400],  # Condition 1 active window
    ]
)
</pre></div>
</div>
</div>
<p>You may be wondering: what about interactions? You might very well expect that there is an interaction between category and interaction. You may have the hypothesis that faces vs. objects can only be decoded in the attended and not in the attended condition. We need to extend our design matrix X to include such an interaction:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>interaction = X[:, 0] * X[:, 1]
X = np.column_stack(
    [X, interaction]
)  # Add a column for the interaction between category and attention
</pre></div>
</div>
</div>
<p>So if you want to inject an interaction effect at a particular time point, you simply need to add one more effect (i.e. the third column) at the time point of your choice. To keep things simple here, we will keep the interaction to 0.</p>
</section>
<section id="4.-Simulating-the-Data">
<h1>4. Simulating the Data<a class="headerlink" href="#4.-Simulating-the-Data" title="Link to this heading">#</a></h1>
<p>So far, we have created our design matrix X, we know that a trial lasts from -0.250 to 1.0s from stimulus onset (i.e. 250ms baseline and 1s after stimulus onset), and we have specified when and what effects we want to have. We need to specify a few more things regarding our data:</p>
<ul class="simple">
<li><p>n_channels: the number of channels of the MEG/EEG recordings we plan to analyze</p></li>
<li><p>sfreq: the sampling frequency of our signal</p></li>
<li><p>n_subjects: the number of subjects for our virtual data set</p></li>
<li><p>s: observation noise</p></li>
<li><p>spat_cov: the spatial covariance of the data we want to simulate</p></li>
</ul>
<p>The aim of this toolbox is to provide a way to test whether analysis pipelines you have designed are able to detect effects that are actually present in your data. So you have to specify parameters that match your actual data: same number of channels, same number of subjects. For this tutorial, let’s say we are working with an EEG system recording <strong>32 channels</strong> and that we collected <strong>20 participants</strong>.</p>
<p>We also recommend that the observation noise and spatial covariance matches your actual data, as it will ensure that the simulated data are representative of the data that you analyze and that the sensitivity and specificity of your pipeline on the simulated data is representative of how they will perform on your real data. We will see in a later tutorial how you can estimate these parameters from your data, but for now we will keep it simple. We will set the observation noise (i.e. variance) to
0.5, and pretend that there is no spatial covariance:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_channels = 32  # EEG system with 32 electrodes
n_subjects = 20  # Recording from 20 subjects
noise_std = 1 / 2  # Variance of the data
spat_cov = None  # Assuming that the data of each sensor are independent
sfreq = 50  # Simulating data at 50Hz
</pre></div>
</div>
</div>
<p>With everything specified, we are now ready to simulate the data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from meeg_simulator import simulate_data

epochs = simulate_data(
    X,  # Design matrix
    noise_std,  # Observation noise
    n_channels,  # Number of channelss
    n_subjects,  # Number of subjects
    -0.25,
    1.0,  # Start and end of epochs
    sfreq,  # Sampling frequency of the data
    t_win,  # Time window of the effects
    effects,  # Which effects
    spat_cov=spat_cov,  # Spatial covariance of the data
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
0 bad epochs dropped
</pre></div></div>
</div>
</section>
<section id="5.-Vizualizing-the-data:">
<h1>5. Vizualizing the data:<a class="headerlink" href="#5.-Vizualizing-the-data:" title="Link to this heading">#</a></h1>
<p>We can have a quick look at our simulated data. It won’t look like much, given that we have simulated multivariate effects without much else at all. It won’t look like actual MEG/EEG data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>epochs[0].plot_image(picks=&quot;eeg&quot;, combine=&quot;mean&quot;, scalings=dict(eeg=1))
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Not setting metadata
160 matching events found
No baseline correction applied
0 projection items activated
combining channels using &#34;mean&#34;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_using_meeg_simulator_13_1.png" src="../_images/tutorial_using_meeg_simulator_13_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;Figure size 640x480 with 3 Axes&gt;]
</pre></div></div>
</div>
</section>
<section id="6.-Decoding-analysis">
<h1>6. Decoding analysis<a class="headerlink" href="#6.-Decoding-analysis" title="Link to this heading">#</a></h1>
<section id="6.1.-Within-subject-analysis:">
<h2>6.1. Within subject analysis:<a class="headerlink" href="#6.1.-Within-subject-analysis:" title="Link to this heading">#</a></h2>
<p>We can try to decode each of the labels of interest (face vs. objects and attended vs. unattended) for a given subject and we will see that these effects are present at the expected time points:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
import numpy as np
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from mne.decoding import SlidingEstimator, cross_val_multiscore

# Create the classifier:
clf = make_pipeline(StandardScaler(), SVC())

# Time resolved
time_decod = SlidingEstimator(clf, n_jobs=None, scoring=&quot;roc_auc&quot;, verbose=True)

# Extract the data:
data = epochs[0].get_data()

# Decode faces vs. objects:
mapping = {1: &quot;Face&quot;, -1: &quot;Object&quot;}
cate_lbl = np.array([mapping[val] for val in X[:, 0]])
scores_category = np.mean(
    cross_val_multiscore(
        time_decod, data, cate_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
    ),
    axis=0,
)

# Decode attended vs. unattended:
mapping = {1: &quot;Attended&quot;, -1: &quot;Unattended&quot;}
att_lbl = np.array([mapping[val] for val in X[:, 1]])
scores_attention = np.mean(
    cross_val_multiscore(
        time_decod, data, att_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
    ),
    axis=0,
)

# Plot
fig, ax = plt.subplots()
ax.plot(epochs[0].times, scores_category, label=&quot;category&quot;)
ax.plot(epochs[0].times, scores_attention, label=&quot;attention&quot;)
ax.axhline(0.5, color=&quot;k&quot;, linestyle=&quot;--&quot;, label=&quot;chance&quot;)
ax.set_xlim([epochs[0].times[0], epochs[0].times[-1]])
ax.set_xlabel(&quot;Times&quot;)
ax.set_ylabel(&quot;AUC&quot;)  # Area Under the Curve
ax.legend()
ax.axvline(0.0, color=&quot;k&quot;, linestyle=&quot;-&quot;)
ax.set_title(&quot;Sensor space decoding&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "46aa50ffb09e460f81cf1619452feda9", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6b21baa1addb48608cfdadc299e62e7a", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f45b092fc2a84fe3a16daa10091119fc", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "27ac14e8d7474644b151dffdab826c62", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6f1b85c13ab94073bc02bfda1fe1af41", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c45416fd27f641cf832c7747f4fcd0b8", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2328eec8a2ab4fa887f59543f7a37d10", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "3cb56393a3a842a6b96ff1fc9ee3b6fe", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fd96b86f6a394fe8a1db49b8b44872ce", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "4db7b5d900894c98bc2f3ecd6aa76bf6", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;Sensor space decoding&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_using_meeg_simulator_15_11.png" src="../_images/tutorial_using_meeg_simulator_15_11.png" />
</div>
</div>
</section>
<section id="6.2.-Group-level-analysis">
<h2>6.2. Group level analysis<a class="headerlink" href="#6.2.-Group-level-analysis" title="Link to this heading">#</a></h2>
<p>We simulated the data of 20 subjects, so we can investigate the evidence for decoding of the experimental manipulations at the group level. First, we need to perform the decoding on every single subject:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from mne.stats import permutation_cluster_1samp_test, bootstrap_confidence_interval

scores_category = []
scores_attention = []

# Loop through each subject:
for epo in epochs:
    # Extract the data:
    data = epo.get_data()
    # Classification of category
    scores_category.append(
        np.mean(
            cross_val_multiscore(
                time_decod, data, cate_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
            ),
            axis=0,
        )
    )
    # Classification of attention:
    scores_attention.append(
        np.mean(
            cross_val_multiscore(
                time_decod, data, att_lbl, cv=5, n_jobs=None, verbose=&quot;WARNING&quot;
            ),
            axis=0,
        )
    )

scores_category = np.array(scores_category)
scores_attention = np.array(scores_attention)
</pre></div>
</div>
</div>
<p>We can then apply a cluster based permutation test across subjects to find out when we have an effect:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Cluster based permutation test for the category:
T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(
    scores_category - 0.5,
    n_permutations=1024,
    tail=1,
    out_type=&quot;mask&quot;,
    verbose=True,
)
sig_mask_cate = np.zeros(len(epochs[0].times), dtype=bool)
for c, p_val in enumerate(cluster_p_values):
    if p_val &lt; 0.05:
        sig_mask_cate[clusters[c]] = True

# Cluster based permutation test for the attention:
T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(
    scores_attention - 0.5,
    n_permutations=1024,
    tail=1,
    out_type=&quot;mask&quot;,
    verbose=True,
)
sig_mask_att = np.zeros(len(epochs[0].times), dtype=bool)
for c, p_val in enumerate(cluster_p_values):
    if p_val &lt; 0.05:
        sig_mask_att[clusters[c]] = True
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using a threshold of 1.729133
stat_fun(H1): min=-2.8118945312599744 max=7.979713324729878
Running initial clustering …
Found 5 clusters
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "d973b58f95334edcaae7cc212cef5041", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using a threshold of 1.729133
stat_fun(H1): min=-2.327866387411186 max=11.278861985081914
Running initial clustering …
Found 5 clusters
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "8c3c10424dad4686947d2526868c77b9", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>Based on the input to the simulation, we would expect to see a significantly above chance decoding of face vs. object from 0.1 to 0.2 s, and then of attention from 0.3 to 0.4s. Let’s check whether that is the case:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Compute the confidence intervals:
ci_low_cate, ci_up_cate = bootstrap_confidence_interval(scores_category)
ci_low_att, ci_up_att = bootstrap_confidence_interval(scores_attention)

fig, ax = plt.subplots()
ax.plot(epochs[0].times, np.mean(scores_category, axis=0), label=&quot;category&quot;, color=&quot;b&quot;)
ax.fill_between(epochs[0].times, ci_low_cate, ci_up_cate, alpha=0.3, color=&quot;b&quot;)
ax.plot(
    epochs[0].times[sig_mask_cate],
    np.ones(np.sum(sig_mask_cate)) * 0.4,
    marker=&quot;o&quot;,
    linestyle=&quot;None&quot;,
    color=&quot;b&quot;,
)

ax.plot(
    epochs[0].times, np.mean(scores_attention, axis=0), label=&quot;attention&quot;, color=&quot;g&quot;
)
ax.fill_between(epochs[0].times, ci_low_att, ci_up_att, alpha=0.3, color=&quot;g&quot;)
ax.plot(
    epochs[0].times[sig_mask_att],
    np.ones(np.sum(sig_mask_att)) * 0.4,
    marker=&quot;o&quot;,
    linestyle=&quot;None&quot;,
    color=&quot;g&quot;,
)
ax.axhline(0.5, color=&quot;k&quot;, linestyle=&quot;--&quot;, label=&quot;chance&quot;)
ax.set_xlim([epochs[0].times[0], epochs[0].times[-1]])
ax.set_xlabel(&quot;Times&quot;)
ax.legend()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x1591607f890&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_using_meeg_simulator_21_1.png" src="../_images/tutorial_using_meeg_simulator_21_1.png" />
</div>
</div>
<p>Just as one would expect, we find significant decoding in the expected time windows. This makes designing decoding analysis (or any multivariate techniques such as RSA) very easy, as one can be sure that mistakes crept in, and that the pipeline is sensitive and specific enough</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Motivation and Overview</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Defining-an-Experimental-Design">1. Defining an Experimental Design</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#3.-Specifying-Time-Windows-for-the-Effects">3. Specifying Time Windows for the Effects</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#4.-Simulating-the-Data">4. Simulating the Data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#5.-Vizualizing-the-data:">5. Vizualizing the data:</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#6.-Decoding-analysis">6. Decoding analysis</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#6.1.-Within-subject-analysis:">6.1. Within subject analysis:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#6.2.-Group-level-analysis">6.2. Group level analysis</a></li>
</ul>
</li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/tutorial/using_meeg_simulator.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, Alex Lepauvre.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>